{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üè• Medicine Demand Forecasting - Model Training\n",
    "## Barangay Health Center Management System\n",
    "\n",
    "**Gradient Boosting Regression Model Training Notebook**\n",
    "\n",
    "This notebook trains machine learning models to forecast monthly, quarterly, and seasonal medicine demand.\n",
    "\n",
    "### Features:\n",
    "- ‚úÖ Train Gradient Boosting models for each medicine\n",
    "- ‚úÖ Monthly predictions (1-12 months ahead)\n",
    "- ‚úÖ Quarterly predictions\n",
    "- ‚úÖ Seasonal predictions (Philippine seasons)\n",
    "- ‚úÖ Model evaluation and validation\n",
    "- ‚úÖ Export trained models for VPS deployment\n",
    "\n",
    "### Requirements:\n",
    "- Database export (CSV or SQL) with dispensing history\n",
    "- Or direct MySQL database connection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas numpy scikit-learn joblib matplotlib seaborn plotly\n",
    "!pip install -q sqlalchemy mysql-connector-python\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## üìö Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÖ Current Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configuration"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_DIR = \"trained_models\"\n",
    "RESULTS_DIR = \"forecast_results\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# Create directories\n",
    "for directory in [MODEL_DIR, RESULTS_DIR, DATA_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Philippine seasons\n",
    "SEASONS = {\n",
    "    'Dry Season (Tag-init)': [3, 4, 5],        # March-May: Hot dry\n",
    "    'Wet Season (Tag-ulan)': [6, 7, 8, 9],     # June-Sept: Southwest monsoon\n",
    "    'Cool Dry (Amihan)': [12, 1, 2],           # Dec-Feb: Northeast monsoon\n",
    "    'Transition': [10, 11]                      # Oct-Nov: Transition\n",
    "}\n",
    "\n",
    "def get_season(month):\n",
    "    \"\"\"Get Philippine season from month.\"\"\"\n",
    "    for season, months in SEASONS.items():\n",
    "        if month in months:\n",
    "            return season\n",
    "    return 'Transition'\n",
    "\n",
    "print(\"‚úÖ Configuration complete!\")\n",
    "print(f\"üìÅ Model directory: {MODEL_DIR}\")\n",
    "print(f\"üìÅ Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_upload"
   },
   "source": [
    "## üì§ Step 4: Upload Data\n",
    "\n",
    "You have **two options** to load data:\n",
    "\n",
    "### Option A: Upload CSV files\n",
    "Required files:\n",
    "- `medicine_dispensing.csv` (columns: med_name, quantity_given, date_given, category)\n",
    "- `medicines.csv` (columns: med_name, category)\n",
    "- `holidays.csv` (optional - columns: event_date, is_national_holiday)\n",
    "\n",
    "### Option B: Connect to MySQL database directly\n",
    "- Provide database credentials below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Choose your data loading method\n",
    "USE_CSV = True  # Set to False if using direct database connection\n",
    "\n",
    "if USE_CSV:\n",
    "    print(\"üì§ Upload your CSV files:\")\n",
    "    print(\"\\nRequired: medicine_dispensing.csv\")\n",
    "    print(\"Required: medicines.csv\")\n",
    "    print(\"Optional: holidays.csv\")\n",
    "    print(\"\\nClick 'Choose Files' to upload...\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Move uploaded files to data directory\n",
    "    for filename in uploaded.keys():\n",
    "        os.rename(filename, os.path.join(DATA_DIR, filename))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Uploaded {len(uploaded)} file(s)\")\n",
    "else:\n",
    "    print(\"üìä Using direct database connection (configure in next cell)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db_config"
   },
   "source": [
    "## üîå Step 5: Database Connection (Optional)\n",
    "\n",
    "**Only run this if USE_CSV = False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "db_connection"
   },
   "outputs": [],
   "source": [
    "# Database configuration (only if not using CSV)\n",
    "if not USE_CSV:\n",
    "    from sqlalchemy import create_engine\n",
    "    \n",
    "    # ‚ö†Ô∏è IMPORTANT: Don't commit credentials to public repositories!\n",
    "    DB_CONFIG = {\n",
    "        'host': 'your_host_or_ip',  # e.g., '192.168.1.100' or 'your-vps.com'\n",
    "        'user': 'root',\n",
    "        'password': 'your_password',\n",
    "        'database': 'barangay_health_center'\n",
    "    }\n",
    "    \n",
    "    # Create database engine\n",
    "    db_url = f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    engine = create_engine(db_url)\n",
    "    \n",
    "    print(\"‚úÖ Database connection established!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping database connection (using CSV files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_data"
   },
   "source": [
    "## üìä Step 6: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_explore"
   },
   "outputs": [],
   "source": [
    "# Load data based on chosen method\n",
    "if USE_CSV:\n",
    "    # Load from CSV\n",
    "    df_dispensing = pd.read_csv(os.path.join(DATA_DIR, 'medicine_dispensing.csv'))\n",
    "    df_medicines = pd.read_csv(os.path.join(DATA_DIR, 'medicines.csv'))\n",
    "    \n",
    "    # Load holidays if available\n",
    "    holidays_file = os.path.join(DATA_DIR, 'holidays.csv')\n",
    "    if os.path.exists(holidays_file):\n",
    "        df_holidays = pd.read_csv(holidays_file)\n",
    "    else:\n",
    "        df_holidays = pd.DataFrame(columns=['event_date', 'is_national_holiday'])\n",
    "        print(\"‚ö†Ô∏è No holidays.csv found - using empty holiday data\")\n",
    "else:\n",
    "    # Load from database\n",
    "    query_dispensing = \"\"\"\n",
    "        SELECT m.med_name, m.category, ma.quantity_given, DATE(ma.date_given) AS date_given\n",
    "        FROM medicine_assistance ma\n",
    "        JOIN medicines m ON ma.med_id = m.med_id\n",
    "        WHERE ma.date_given IS NOT NULL\n",
    "    \"\"\"\n",
    "    df_dispensing = pd.read_sql(query_dispensing, engine)\n",
    "    df_medicines = pd.read_sql(\"SELECT DISTINCT med_name, category FROM medicines\", engine)\n",
    "    \n",
    "    try:\n",
    "        df_holidays = pd.read_sql(\"SELECT event_date, is_national_holiday FROM external_events\", engine)\n",
    "    except:\n",
    "        df_holidays = pd.DataFrame(columns=['event_date', 'is_national_holiday'])\n",
    "\n",
    "# Display data overview\n",
    "print(\"=\"*80)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìã Dispensing Records: {len(df_dispensing):,}\")\n",
    "print(f\"üíä Unique Medicines: {df_dispensing['med_name'].nunique()}\")\n",
    "print(f\"üìÖ Date Range: {df_dispensing['date_given'].min()} to {df_dispensing['date_given'].max()}\")\n",
    "print(f\"üéâ Holiday Records: {len(df_holidays):,}\")\n",
    "\n",
    "print(\"\\nüìä Sample Dispensing Data:\")\n",
    "display(df_dispensing.head(10))\n",
    "\n",
    "print(\"\\nüìà Medicine Categories:\")\n",
    "display(df_medicines.groupby('category').size().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocess"
   },
   "source": [
    "## üîß Step 7: Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocessing"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Starting data preprocessing...\\n\")\n",
    "\n",
    "# Convert dates\n",
    "df_dispensing['date_given'] = pd.to_datetime(df_dispensing['date_given'])\n",
    "df_dispensing['period'] = df_dispensing['date_given'].dt.to_period('M')\n",
    "\n",
    "# Get all medicines and date range\n",
    "all_meds = df_medicines['med_name'].dropna().unique().tolist()\n",
    "min_date = df_dispensing['period'].min()\n",
    "max_date = df_dispensing['period'].max()\n",
    "full_period_range = pd.period_range(start=min_date, end=max_date, freq='M')\n",
    "\n",
    "print(f\"üìÖ Creating continuous time series: {min_date} to {max_date} ({len(full_period_range)} months)\")\n",
    "\n",
    "# Create continuous time series (all medicine-month combinations)\n",
    "multi_index = pd.MultiIndex.from_product(\n",
    "    [all_meds, full_period_range],\n",
    "    names=['med_name', 'period']\n",
    ")\n",
    "monthly_template = pd.DataFrame(index=multi_index).reset_index()\n",
    "monthly_template['date_start'] = monthly_template['period'].apply(lambda x: x.start_time)\n",
    "\n",
    "# Aggregate dispensing data by month\n",
    "monthly_usage = df_dispensing.groupby(['med_name', 'period'])['quantity_given'].sum().reset_index()\n",
    "\n",
    "# Merge and fill gaps with zeros\n",
    "monthly_df = monthly_template.merge(monthly_usage, on=['med_name', 'period'], how='left')\n",
    "monthly_df['total_quantity'] = monthly_df['quantity_given'].fillna(0)\n",
    "\n",
    "# Add medicine categories\n",
    "med_categories = df_medicines.set_index('med_name')['category'].to_dict()\n",
    "monthly_df['category'] = monthly_df['med_name'].map(med_categories)\n",
    "\n",
    "print(\"‚úÖ Base time series created\")\n",
    "print(f\"   Total records: {len(monthly_df):,}\")\n",
    "\n",
    "# === FEATURE ENGINEERING ===\n",
    "print(\"\\nüé® Engineering features...\")\n",
    "\n",
    "# Time-based features\n",
    "monthly_df['month_of_year'] = monthly_df['date_start'].dt.month\n",
    "monthly_df['quarter'] = monthly_df['date_start'].dt.quarter\n",
    "monthly_df['year'] = monthly_df['date_start'].dt.year\n",
    "monthly_df['days_in_month'] = monthly_df['date_start'].dt.days_in_month\n",
    "\n",
    "# Philippine season\n",
    "monthly_df['season'] = monthly_df['month_of_year'].apply(get_season)\n",
    "\n",
    "# Cyclical encoding (better for seasonality)\n",
    "monthly_df['month_sin'] = np.sin(2 * np.pi * monthly_df['month_of_year'] / 12)\n",
    "monthly_df['month_cos'] = np.cos(2 * np.pi * monthly_df['month_of_year'] / 12)\n",
    "\n",
    "# Lag features (previous months)\n",
    "for lag in [1, 2, 3, 6, 12]:\n",
    "    monthly_df[f'lag_{lag}'] = monthly_df.groupby('med_name')['total_quantity'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "for window in [3, 6, 12]:\n",
    "    monthly_df[f'rolling_mean_{window}'] = monthly_df.groupby('med_name')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "    monthly_df[f'rolling_std_{window}'] = monthly_df.groupby('med_name')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).std().fillna(0)\n",
    "    )\n",
    "\n",
    "# Time index (trend)\n",
    "monthly_df['time_index'] = monthly_df.groupby('med_name').cumcount()\n",
    "\n",
    "# Holiday features\n",
    "if len(df_holidays) > 0:\n",
    "    df_holidays['event_date'] = pd.to_datetime(df_holidays['event_date'])\n",
    "    df_holidays['period'] = df_holidays['event_date'].dt.to_period('M')\n",
    "    monthly_events = df_holidays.groupby('period')['is_national_holiday'].sum().reset_index()\n",
    "    monthly_events.columns = ['period', 'total_holidays']\n",
    "    \n",
    "    monthly_df = monthly_df.merge(monthly_events, on='period', how='left')\n",
    "    monthly_df['total_holidays'] = monthly_df['total_holidays'].fillna(0)\n",
    "    monthly_df['holiday_ratio'] = monthly_df['total_holidays'] / monthly_df['days_in_month']\n",
    "    print(\"   ‚úÖ Holiday features added\")\n",
    "else:\n",
    "    monthly_df['total_holidays'] = 0\n",
    "    monthly_df['holiday_ratio'] = 0\n",
    "    print(\"   ‚ö†Ô∏è No holiday data - using zeros\")\n",
    "\n",
    "# Category encoding\n",
    "category_mapping = {cat: idx for idx, cat in enumerate(monthly_df['category'].unique())}\n",
    "monthly_df['category_encoded'] = monthly_df['category'].map(category_mapping)\n",
    "\n",
    "print(\"‚úÖ Feature engineering complete!\")\n",
    "print(f\"   Total features: {len(monthly_df.columns)}\")\n",
    "\n",
    "# Display feature summary\n",
    "print(\"\\nüìä Feature Summary:\")\n",
    "display(monthly_df.describe())\n",
    "\n",
    "print(\"\\nüéØ Sample processed data:\")\n",
    "display(monthly_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## üìà Step 8: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization"
   },
   "outputs": [],
   "source": [
    "# Top medicines by total dispensing\n",
    "top_medicines = monthly_df.groupby('med_name')['total_quantity'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "top_medicines.plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 10 Medicines by Total Dispensing', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Total Quantity Dispensed', fontsize=12)\n",
    "plt.ylabel('Medicine', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Monthly trend for top medicine\n",
    "top_med = top_medicines.index[0]\n",
    "top_med_data = monthly_df[monthly_df['med_name'] == top_med].sort_values('date_start')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(top_med_data['date_start'], top_med_data['total_quantity'], marker='o', linewidth=2)\n",
    "plt.title(f'Monthly Dispensing Trend: {top_med}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Quantity Dispensed', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Seasonal distribution\n",
    "seasonal_dist = monthly_df.groupby('season')['total_quantity'].sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "seasonal_dist.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
    "plt.title('Total Dispensing by Philippine Season', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Total Quantity', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üéØ Step 9: Train Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_training"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING GRADIENT BOOSTING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Feature columns for training\n",
    "feature_cols = [\n",
    "    'month_of_year', 'quarter', 'month_sin', 'month_cos',\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_6', 'lag_12',\n",
    "    'rolling_mean_3', 'rolling_mean_6', 'rolling_mean_12',\n",
    "    'rolling_std_3', 'rolling_std_6', 'rolling_std_12',\n",
    "    'time_index', 'holiday_ratio', 'days_in_month',\n",
    "    'category_encoded'\n",
    "]\n",
    "\n",
    "models = {}\n",
    "model_metrics = []\n",
    "trained_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "print(f\"\\nüéØ Training models for {len(all_meds)} medicines...\\n\")\n",
    "\n",
    "for i, med in enumerate(all_meds, 1):\n",
    "    # Get medicine data\n",
    "    med_data = monthly_df[monthly_df['med_name'] == med].copy()\n",
    "    \n",
    "    # Remove rows with NaN in critical features\n",
    "    med_data_clean = med_data.dropna(subset=['lag_1', 'lag_2', 'lag_3'])\n",
    "    \n",
    "    if len(med_data_clean) < 6:\n",
    "        skipped_count += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"   Progress: {i}/{len(all_meds)} (Trained: {trained_count}, Skipped: {skipped_count})\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = med_data_clean[feature_cols].values\n",
    "    y = med_data_clean['total_quantity'].values\n",
    "    \n",
    "    # Train-test split\n",
    "    if len(X) >= 12:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = None, None\n",
    "    \n",
    "    # Train model\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        min_samples_split=4,\n",
    "        min_samples_leaf=2,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        loss='squared_error'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    if X_test is not None:\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        model_metrics.append({\n",
    "            'medicine': med,\n",
    "            'category': med_data.iloc[0]['category'],\n",
    "            'train_samples': len(X_train),\n",
    "            'test_samples': len(X_test),\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2_score': r2\n",
    "        })\n",
    "    else:\n",
    "        mae, rmse, r2 = None, None, None\n",
    "    \n",
    "    # Store model\n",
    "    models[med] = {\n",
    "        'model': model,\n",
    "        'feature_cols': feature_cols,\n",
    "        'last_data': med_data.iloc[-1].to_dict(),\n",
    "        'category': med_data.iloc[0]['category'],\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    # Save model to disk\n",
    "    model_filename = f\"{med.replace(' ', '_')}_enhanced_gbr.joblib\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    trained_count += 1\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"   Progress: {i}/{len(all_meds)} (Trained: {trained_count}, Skipped: {skipped_count})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ Training Complete!\")\n",
    "print(f\"   Total medicines: {len(all_meds)}\")\n",
    "print(f\"   Models trained: {trained_count}\")\n",
    "print(f\"   Skipped (insufficient data): {skipped_count}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display model performance\n",
    "if model_metrics:\n",
    "    df_metrics = pd.DataFrame(model_metrics)\n",
    "    print(\"\\nüìä Model Performance Summary:\")\n",
    "    print(f\"   Average MAE: {df_metrics['mae'].mean():.2f}\")\n",
    "    print(f\"   Average RMSE: {df_metrics['rmse'].mean():.2f}\")\n",
    "    print(f\"   Average R¬≤: {df_metrics['r2_score'].mean():.3f}\")\n",
    "    \n",
    "    print(\"\\nüèÜ Top 10 Best Performing Models (by R¬≤):\")\n",
    "    display(df_metrics.sort_values('r2_score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "forecast"
   },
   "source": [
    "## üîÆ Step 10: Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "forecasting"
   },
   "outputs": [],
   "source": [
    "def generate_future_features(models, med_name, months_ahead):\n",
    "    \"\"\"Generate future feature vectors for prediction.\"\"\"\n",
    "    last_data = models[med_name]['last_data']\n",
    "    feature_cols = models[med_name]['feature_cols']\n",
    "    \n",
    "    future_features = []\n",
    "    last_date = pd.to_datetime(last_data['date_start'])\n",
    "    \n",
    "    for i in range(1, months_ahead + 1):\n",
    "        future_date = last_date + relativedelta(months=i)\n",
    "        \n",
    "        # Time features\n",
    "        month = future_date.month\n",
    "        quarter = (month - 1) // 3 + 1\n",
    "        month_sin = np.sin(2 * np.pi * month / 12)\n",
    "        month_cos = np.cos(2 * np.pi * month / 12)\n",
    "        days_in_month = calendar.monthrange(future_date.year, future_date.month)[1]\n",
    "        time_index = last_data['time_index'] + i\n",
    "        \n",
    "        # Lag features\n",
    "        if i == 1:\n",
    "            lag_1 = last_data['total_quantity']\n",
    "            lag_2 = last_data.get('lag_1', lag_1)\n",
    "            lag_3 = last_data.get('lag_2', lag_1)\n",
    "            lag_6 = last_data.get('lag_5', lag_1)\n",
    "            lag_12 = last_data.get('lag_11', lag_1)\n",
    "        else:\n",
    "            lag_1 = future_features[i-2][4] if i > 1 else last_data['total_quantity']\n",
    "            lag_2 = future_features[i-3][4] if i > 2 else last_data.get('lag_1', lag_1)\n",
    "            lag_3 = future_features[i-4][4] if i > 3 else last_data.get('lag_2', lag_1)\n",
    "            lag_6 = future_features[i-7][4] if i > 6 else last_data.get('lag_5', lag_1)\n",
    "            lag_12 = future_features[i-13][4] if i > 12 else last_data.get('lag_11', lag_1)\n",
    "        \n",
    "        # Rolling stats (approximate)\n",
    "        rolling_mean_3 = last_data.get('rolling_mean_3', lag_1)\n",
    "        rolling_mean_6 = last_data.get('rolling_mean_6', lag_1)\n",
    "        rolling_mean_12 = last_data.get('rolling_mean_12', lag_1)\n",
    "        rolling_std_3 = last_data.get('rolling_std_3', 0)\n",
    "        rolling_std_6 = last_data.get('rolling_std_6', 0)\n",
    "        rolling_std_12 = last_data.get('rolling_std_12', 0)\n",
    "        \n",
    "        holiday_ratio = last_data.get('holiday_ratio', 0.1)\n",
    "        category_encoded = last_data.get('category_encoded', 0)\n",
    "        \n",
    "        features = [\n",
    "            month, quarter, month_sin, month_cos,\n",
    "            lag_1, lag_2, lag_3, lag_6, lag_12,\n",
    "            rolling_mean_3, rolling_mean_6, rolling_mean_12,\n",
    "            rolling_std_3, rolling_std_6, rolling_std_12,\n",
    "            time_index, holiday_ratio, days_in_month,\n",
    "            category_encoded\n",
    "        ]\n",
    "        \n",
    "        future_features.append(features)\n",
    "    \n",
    "    return np.array(future_features)\n",
    "\n",
    "def calculate_seasonal_predictions(monthly_preds):\n",
    "    \"\"\"Calculate seasonal predictions.\"\"\"\n",
    "    current_month = datetime.now().month\n",
    "    seasonal_preds = {}\n",
    "    \n",
    "    month_predictions = {}\n",
    "    for i, pred in enumerate(monthly_preds[:12]):\n",
    "        month = ((current_month + i - 1) % 12) + 1\n",
    "        month_predictions[month] = pred\n",
    "    \n",
    "    for season_name, months in SEASONS.items():\n",
    "        season_values = [month_predictions.get(m, 0) for m in months if m in month_predictions]\n",
    "        if season_values:\n",
    "            seasonal_preds[season_name] = round(float(np.mean(season_values)), 2)\n",
    "        else:\n",
    "            seasonal_preds[season_name] = 0\n",
    "    \n",
    "    return seasonal_preds\n",
    "\n",
    "# Generate forecasts\n",
    "print(\"üîÆ Generating forecasts for all trained models...\\n\")\n",
    "\n",
    "all_forecasts = {}\n",
    "months_ahead = 12\n",
    "\n",
    "for med_name in models.keys():\n",
    "    try:\n",
    "        # Generate future features\n",
    "        X_future = generate_future_features(models, med_name, months_ahead)\n",
    "        \n",
    "        # Predict\n",
    "        model = models[med_name]['model']\n",
    "        predictions = model.predict(X_future)\n",
    "        predictions = np.maximum(predictions, 0)  # Ensure non-negative\n",
    "        \n",
    "        # Store monthly predictions\n",
    "        monthly_preds = [round(float(p), 2) for p in predictions]\n",
    "        \n",
    "        # Calculate quarterly\n",
    "        quarterly_preds = []\n",
    "        for q in range(0, len(monthly_preds), 3):\n",
    "            quarter_avg = np.mean(monthly_preds[q:q+3])\n",
    "            quarterly_preds.append(round(float(quarter_avg), 2))\n",
    "        \n",
    "        # Calculate seasonal\n",
    "        seasonal_preds = calculate_seasonal_predictions(monthly_preds)\n",
    "        \n",
    "        all_forecasts[med_name] = {\n",
    "            'monthly': {\n",
    "                'next_1_month': monthly_preds[0],\n",
    "                'next_2_months': monthly_preds[1],\n",
    "                'next_3_months': monthly_preds[2],\n",
    "                'all_months': monthly_preds\n",
    "            },\n",
    "            'quarterly': {\n",
    "                'next_quarter': quarterly_preds[0],\n",
    "                'all_quarters': quarterly_preds\n",
    "            },\n",
    "            'seasonal': seasonal_preds,\n",
    "            'model_performance': {\n",
    "                'mae': models[med_name].get('mae'),\n",
    "                'r2_score': models[med_name].get('r2')\n",
    "            },\n",
    "            'category': models[med_name]['category']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error forecasting {med_name}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Generated forecasts for {len(all_forecasts)} medicines\")\n",
    "\n",
    "# Display top predictions\n",
    "sorted_forecasts = sorted(\n",
    "    all_forecasts.items(),\n",
    "    key=lambda x: x[1]['monthly']['next_1_month'],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "print(\"\\nüìà TOP 10 HIGHEST PREDICTED DEMAND (Next Month):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Medicine':<40} {'Category':<20} {'Predicted Qty':<15}\")\n",
    "print(\"-\" * 80)\n",
    "for med, data in sorted_forecasts:\n",
    "    print(f\"{med:<40} {data['category']:<20} {data['monthly']['next_1_month']:<15.2f}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize_forecast"
   },
   "source": [
    "## üìä Step 11: Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz_forecasts"
   },
   "outputs": [],
   "source": [
    "# Visualize forecast for top medicine\n",
    "top_med = sorted_forecasts[0][0]\n",
    "top_med_forecast = all_forecasts[top_med]\n",
    "\n",
    "# Get historical data\n",
    "historical = monthly_df[monthly_df['med_name'] == top_med].sort_values('date_start')\n",
    "\n",
    "# Create future dates\n",
    "last_date = historical['date_start'].max()\n",
    "future_dates = [last_date + relativedelta(months=i) for i in range(1, 13)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "# Historical\n",
    "plt.plot(historical['date_start'], historical['total_quantity'], \n",
    "         marker='o', linewidth=2, label='Historical', color='steelblue')\n",
    "\n",
    "# Forecast\n",
    "plt.plot(future_dates, top_med_forecast['monthly']['all_months'],\n",
    "         marker='s', linewidth=2, linestyle='--', label='Forecast', color='orangered')\n",
    "\n",
    "plt.axvline(x=last_date, color='gray', linestyle=':', linewidth=2, label='Forecast Start')\n",
    "plt.title(f'Medicine Demand Forecast: {top_med}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Quantity', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Seasonal forecast visualization\n",
    "seasonal_data = top_med_forecast['seasonal']\n",
    "seasons = list(seasonal_data.keys())\n",
    "values = list(seasonal_data.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "plt.bar(seasons, values, color=colors)\n",
    "plt.title(f'Seasonal Demand Forecast: {top_med}', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Predicted Average Quantity', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## üíæ Step 12: Save Results & Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_export"
   },
   "outputs": [],
   "source": [
    "print(\"üíæ Saving forecast results...\\n\")\n",
    "\n",
    "# Save comprehensive forecast\n",
    "output_file = os.path.join(RESULTS_DIR, 'enhanced_forecast_results.json')\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(all_forecasts, f, indent=4)\n",
    "print(f\"‚úÖ Saved: {output_file}\")\n",
    "\n",
    "# Save backward-compatible monthly forecast\n",
    "monthly_simple = {med: data['monthly']['next_1_month'] for med, data in all_forecasts.items()}\n",
    "with open(os.path.join(RESULTS_DIR, 'forecast_results.json'), 'w') as f:\n",
    "    json.dump(monthly_simple, f, indent=4)\n",
    "print(f\"‚úÖ Saved: {RESULTS_DIR}/forecast_results.json\")\n",
    "\n",
    "# Save seasonal forecast\n",
    "seasonal_forecast = {\n",
    "    med: {\n",
    "        'next_month_pred': data['monthly']['next_1_month'],\n",
    "        'quarter_avg_pred': data['quarterly']['next_quarter']\n",
    "    }\n",
    "    for med, data in all_forecasts.items()\n",
    "}\n",
    "with open(os.path.join(RESULTS_DIR, 'seasonal_forecast.json'), 'w') as f:\n",
    "    json.dump(seasonal_forecast, f, indent=4)\n",
    "print(f\"‚úÖ Saved: {RESULTS_DIR}/seasonal_forecast.json\")\n",
    "\n",
    "# Save model performance metrics\n",
    "if model_metrics:\n",
    "    df_metrics.to_csv(os.path.join(RESULTS_DIR, 'model_performance.csv'), index=False)\n",
    "    print(f\"‚úÖ Saved: {RESULTS_DIR}/model_performance.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ EXPORT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Trained Models: {len(models)} saved in '{MODEL_DIR}/'\")\n",
    "print(f\"‚úÖ Forecast Results: {len(all_forecasts)} saved in '{RESULTS_DIR}/'\")\n",
    "print(f\"‚úÖ Total Files: {len(os.listdir(MODEL_DIR)) + len(os.listdir(RESULTS_DIR))}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üì• Step 13: Download Models & Results for VPS Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì¶ Preparing deployment package...\\n\")\n",
    "\n",
    "# Create deployment package\n",
    "deployment_dir = 'medicine_forecast_deployment'\n",
    "os.makedirs(deployment_dir, exist_ok=True)\n",
    "\n",
    "# Copy models\n",
    "shutil.copytree(MODEL_DIR, os.path.join(deployment_dir, 'models'), dirs_exist_ok=True)\n",
    "print(f\"‚úÖ Copied {len(os.listdir(MODEL_DIR))} models\")\n",
    "\n",
    "# Copy results\n",
    "shutil.copytree(RESULTS_DIR, os.path.join(deployment_dir, 'forecast_results'), dirs_exist_ok=True)\n",
    "print(f\"‚úÖ Copied {len(os.listdir(RESULTS_DIR))} result files\")\n",
    "\n",
    "# Create README\n",
    "readme_content = f\"\"\"# Medicine Demand Forecasting - Deployment Package\n",
    "\n",
    "## Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Contents:\n",
    "- `models/`: {len(os.listdir(MODEL_DIR))} trained Gradient Boosting models (.joblib files)\n",
    "- `forecast_results/`: Forecast predictions (JSON files)\n",
    "\n",
    "## Deployment Instructions:\n",
    "\n",
    "1. **Upload to VPS:**\n",
    "   - Upload the entire `models/` directory to `/home/user/health/models/`\n",
    "   - Upload forecast JSON files to `/home/user/health/forecast_results/`\n",
    "\n",
    "2. **Install Dependencies on VPS:**\n",
    "   ```bash\n",
    "   pip install pandas numpy scikit-learn joblib sqlalchemy mysql-connector-python\n",
    "   ```\n",
    "\n",
    "3. **Run Forecasting:**\n",
    "   - Use `forecast_enhanced_gbr.py` to generate new forecasts\n",
    "   - Models will be loaded from the `models/` directory\n",
    "\n",
    "4. **API Integration:**\n",
    "   - The forecast API will read from JSON files in `forecast_results/`\n",
    "   - Files: `forecast_results.json`, `seasonal_forecast.json`, `enhanced_forecast_results.json`\n",
    "\n",
    "## Model Information:\n",
    "- Algorithm: Gradient Boosting Regressor\n",
    "- Features: 19 (time, lag, rolling stats, holidays, categories)\n",
    "- Predictions: Monthly (1-12 months), Quarterly, Seasonal\n",
    "\n",
    "## Notes:\n",
    "- Models are pre-trained and ready to use\n",
    "- Re-train periodically as new dispensing data accumulates\n",
    "- Ensure database credentials are configured in Python scripts\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(deployment_dir, 'README.md'), 'w') as f:\n",
    "    f.write(readme_content)\n",
    "print(\"‚úÖ Created README.md\")\n",
    "\n",
    "# Create deployment script\n",
    "deploy_script = \"\"\"#!/bin/bash\n",
    "# Deployment script for VPS\n",
    "\n",
    "echo \"üöÄ Deploying Medicine Forecasting Models...\"\n",
    "\n",
    "# Set paths\n",
    "TARGET_DIR=\"/home/user/health\"\n",
    "\n",
    "# Copy models\n",
    "echo \"üì¶ Copying models...\"\n",
    "cp -r models/ $TARGET_DIR/models/\n",
    "\n",
    "# Copy forecast results\n",
    "echo \"üìä Copying forecast results...\"\n",
    "cp -r forecast_results/ $TARGET_DIR/forecast_results/\n",
    "\n",
    "echo \"‚úÖ Deployment complete!\"\n",
    "echo \"Run: python3 $TARGET_DIR/forecast_enhanced_gbr.py\"\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(deployment_dir, 'deploy.sh'), 'w') as f:\n",
    "    f.write(deploy_script)\n",
    "os.chmod(os.path.join(deployment_dir, 'deploy.sh'), 0o755)\n",
    "print(\"‚úÖ Created deploy.sh\")\n",
    "\n",
    "# Create ZIP archive\n",
    "print(\"\\nüóúÔ∏è Creating ZIP archive...\")\n",
    "shutil.make_archive('medicine_forecast_deployment', 'zip', deployment_dir)\n",
    "print(\"‚úÖ Created medicine_forecast_deployment.zip\")\n",
    "\n",
    "# Download\n",
    "print(\"\\nüì• Downloading deployment package...\")\n",
    "files.download('medicine_forecast_deployment.zip')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ DEPLOYMENT PACKAGE READY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüì¶ Package Contents:\")\n",
    "print(f\"   - {len(os.listdir(MODEL_DIR))} trained models\")\n",
    "print(f\"   - {len(os.listdir(RESULTS_DIR))} forecast files\")\n",
    "print(\"   - README.md with deployment instructions\")\n",
    "print(\"   - deploy.sh script for VPS setup\")\n",
    "print(\"\\n‚úÖ Download complete! Upload to your VPS and run deploy.sh\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## üìã Training Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. ‚úÖ **Data Processing**: Loaded and preprocessed dispensing records\n",
    "2. ‚úÖ **Feature Engineering**: Created 19 predictive features\n",
    "3. ‚úÖ **Model Training**: Trained Gradient Boosting models for each medicine\n",
    "4. ‚úÖ **Forecasting**: Generated monthly, quarterly, and seasonal predictions\n",
    "5. ‚úÖ **Validation**: Evaluated model performance with MAE, RMSE, R¬≤\n",
    "6. ‚úÖ **Export**: Created deployment package for VPS\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Upload to VPS**: Extract `medicine_forecast_deployment.zip` on your server\n",
    "2. **Run Deployment**: Execute `./deploy.sh` to install models\n",
    "3. **Test Forecasting**: Run `python3 forecast_enhanced_gbr.py`\n",
    "4. **Integrate with Dashboard**: Update PHP dashboard to display forecasts\n",
    "5. **Schedule Retraining**: Set up cron job to retrain models monthly\n",
    "\n",
    "### Model Maintenance:\n",
    "\n",
    "- **Retrain monthly** as new dispensing data accumulates\n",
    "- **Monitor performance** using MAE and R¬≤ scores\n",
    "- **Update features** if new data sources become available\n",
    "- **Adjust parameters** if forecast accuracy drops\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! Your medicine demand forecasting system is ready for production!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Medicine_Demand_Forecasting_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
